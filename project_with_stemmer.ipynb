{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf15061f-2ba6-44cf-bda4-b46db7998c9c",
   "metadata": {},
   "source": [
    "# Projekt\n",
    "\n",
    "## Zadanie 1\n",
    "\n",
    "Przygotuj **`100 dokumentów`** w języku angielskim (nie za długich, po około pół strony) i zapisz je do\n",
    "jednego pliku tekstowego. Dokumenty oddzielaj przynajmniej jedną pustą linią. Podobnie przygotuj\n",
    "plik z **`5 zapytaniami`** (query, Q). Wczytaj dokumenty oraz Q do R (możesz użyć funkcji read.docs()\n",
    "z pliku TM_fun.R). Używając pakietu tm utwórz z wczytanych dokumentów oraz Q korpus i dokonaj\n",
    "standardowego prepocessingu (zamiana na małe litery, usunięcie liczb, usunięcie znaków\n",
    "przystankowych, stemming Portera, usunięcie słów z stoplisty). Następnie zbuduj macierz TDM\n",
    "(w wariantach: **`binarnym`**, **`BOW`** oraz **`TFIDF`**) i dla wszystkich Q znajdź po 5 najbardziej adekwatnych\n",
    "dokumentów. Na koniec wyświetl podsumowanie danych w postaci chmury słów. Powtórz cały\n",
    "eksperyment z tą różnicą, że tym razem nie używaj stemmera Portera (ani żadnego innego).\n",
    "Porównaj i skomentuj oba otrzymane wyniki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b3978-cdef-46fa-be81-d38e5575e363",
   "metadata": {},
   "source": [
    "## # BIBLIOTEKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e22e0-3f59-4d34-b544-bc55dae84213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Narzędzia podstawowe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 2. Wizualizacja\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# 3. Przetwarzanie Języka Naturalnego (NLP) - biblioteka NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# 4. Uczenie Maszynowe i Analiza Tekstu - Biblioteka Scikit-Learn (sklearn)\n",
    "# CountVectorizer: Zamienia tekst na macierz zliczeń (Bag of Words / Binary)\n",
    "# TfidfVectorizer: Zamienia tekst na macierz ważoną (statystyka TF-IDF)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# cosine_similarity: Funkcja do obliczania podobieństwa między wektorami (dokumentami a zapytaniem)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# do zliczenia wystąpień słów w dokumencie\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# konfiguracja nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c519cc-ae17-42dd-b693-58e960045b3a",
   "metadata": {},
   "source": [
    "## # OBIEKTY\n",
    "Tworzymy obiekty, których będziemy używać w funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a5ff9-e876-4b36-ae18-802950c223ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. stopwords - lista słów do usunięcia (np. \"the\", \"a\", \"in\") dla języka angielskiego\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 2. Stemmer Portera - algorytm, który ucina końcówki słów (np. \"running\" -> \"run\")\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bbb5b-0545-44a6-9baa-b83e5c022a58",
   "metadata": {},
   "source": [
    "## # PREPROCESSING\n",
    "#### Czyszczenie tekstu zgodnie z wymaganiami zadania:\n",
    "- `zamiana na małe litery`\n",
    "- `usunięcie liczb`\n",
    "- `usunięcie znaków przystankowych`\n",
    "- `stemming Portera`\n",
    "- `usunięcie słów z stoplisty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4ed5a-bf52-4863-9687-92efbcf77b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, use_stemming=True):\n",
    "    \"\"\"\n",
    "    argumenty: \n",
    "    text - surowy tekst do wyczyszczenia\n",
    "    use_stemming - czy używać stemming, dla porównania jak działa to bez stemmingu trzeba zamienić 'True' na 'False'\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. zamiana na małe litery\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. usunięcie liczb i znaków przystankowych\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # 3. tokenizacja \n",
    "    words = text.split()\n",
    "    \n",
    "    # 4. usunięcie stopwords i stemming\n",
    "    cleaned_words = [] # tworzymy nową listę\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            if use_stemming:\n",
    "                cleaned_words.append(ps.stem(word))\n",
    "            else:\n",
    "                cleaned_words.append(word) \n",
    "    return \" \".join(cleaned_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d30e6-f46f-43d7-8c40-60da27836fc3",
   "metadata": {},
   "source": [
    "## # DOKUMENTY I ZAPYTANIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ca343-e5dd-41de-a63e-434ffb44fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. wczytujemy dokumenty (docs)\n",
    "with open('dokumenty.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_docs = f.read().split('\\n\\n')\n",
    "\n",
    "# 2. wczytujemy zapytania (queries)\n",
    "with open('zapytania.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_queries = f.read().split('\\n')\n",
    "\n",
    "# 3. przetwarzamy dokumenty (wersja ze stemmingiem (True); wersja bez stemmingu (False))\n",
    "clean_docs_stemmed = [preprocess_text(doc, use_stemming=True) for doc in raw_docs if doc.strip()]\n",
    "clean_queries_stemmed = [preprocess_text(query, use_stemming=True) for query in raw_queries if query.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c64b5-52e1-41b7-8627-d3ea5c17c426",
   "metadata": {},
   "source": [
    "## # PRZYKŁAD PREPROCESSINGU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec22c08-d3a2-44fc-8ad2-12550f813076",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tekst oryginalny:\\n{raw_docs[0][:200]}...\")\n",
    "print(f\"\\nTekst po oczyszczeniu (Stemming ON):\\n{clean_docs_stemmed[0][:200]}...\")\n",
    "\n",
    "print(f\"\\nLiczba przetworzonych dokumentów: {len(clean_docs_stemmed)}\")\n",
    "print(f\"Liczba przetworzonych zapytań: {len(clean_queries_stemmed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9224d3-db6f-4d85-b12b-e0bf6a9d9427",
   "metadata": {},
   "source": [
    "## # BUDOWA MACIERZY I WYSZUKIWANIE DOKUMENTÓW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea1497-ae85-4f0d-8a70-b19dbbb09d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_save(vectorizer, docs_clean, queries_clean, docs_raw, method_name, filename):\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"RAPORT WYNIKÓW WYSZUKIWANIA\\n\")\n",
    "        f.write(f\"{'='*120}\\n\")\n",
    "\n",
    "        print(f\"\\n{'='*45} METODA: {method_name} {'='*45}\")\n",
    "        \n",
    "        # 1. tworzenie macierzy\n",
    "        X_docs = vectorizer.fit_transform(docs_clean)\n",
    "    \n",
    "        # 2. transformacja zapytań\n",
    "        X_queries = vectorizer.transform(queries_clean)\n",
    "    \n",
    "        # 3. obliczanie podobieństwa\n",
    "        similarity_matrix = cosine_similarity(X_queries, X_docs)\n",
    "    \n",
    "        # 4. wyświetlanie wyników\n",
    "        for i, query_scores in enumerate(similarity_matrix):\n",
    "            top_indices = query_scores.argsort()[-5:][::-1]\n",
    "\n",
    "            f.write(f\"ZAPYTANIE {i+1}: '{raw_queries[i]}'\\n\")\n",
    "            f.write(f\"-\"*120 + \"\\n\")\n",
    "            \n",
    "            print(f\"\\nZapytanie {i+1}: '{raw_queries[i]}'\")\n",
    "            print(\"-\" * 120)\n",
    "    \n",
    "            for rank, doc_idx in enumerate(top_indices, 1):\n",
    "                score = query_scores[doc_idx]\n",
    "                if score > 0:\n",
    "                    f.write(f\"Rank {rank}. [Dokument {doc_idx+1}] Score: {score:.4f}\\n\")\n",
    "                    snippet = docs_raw[doc_idx][:200].replace('\\n', ' ')\n",
    "                    f.write(f\"Fragment: {snippet}...\\n\\n\")\n",
    "                    \n",
    "                    print(f\"[Dokument {doc_idx+1}] Score: {score:.4f}\")\n",
    "                    print(f\"  Fragment: {docs_raw[doc_idx][:200].replace(chr(10), ' ')}...\")\n",
    "                else:\n",
    "                    f.write(f\"Rank {rank}. [Brak dopasowania]\\n\")\n",
    "                    print(f\"[Dokument {doc_idx+1}] Brak dopasowania (Score: 0.0)\")\n",
    "\n",
    "            f.write(\"\\n\" + \"#\"*120 + \"\\n\\n\")\n",
    "            print(\"-\" * 120)\n",
    "\n",
    "    print(f\"Wyniki zapisano do pliku: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013d7c3-3100-43fd-9739-52b7dd47f629",
   "metadata": {},
   "source": [
    "## # PODGLĄD MACIERZY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffe635-2975-40ef-9d12-7236d4e33dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_matrix_snippet(vectorizer, docs_clean, title):\n",
    "    print(f\"\\n{'='*40} {title} (TOP 10 SŁÓW) {'='*40}\")\n",
    "\n",
    "    # 1. Tworzymy macierz\n",
    "    X = vectorizer.fit_transform(docs_clean)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # 2. Sumujemy kolumny\n",
    "    sum_words = X.sum(axis=0)\n",
    "\n",
    "    # 3. Tworzymy listę par: (słowo, suma)\n",
    "    words_freq = [(word, sum_words[0, idx]) for idx, word in enumerate(feature_names)]\n",
    "\n",
    "    # 4. Sortujemy i bierzemy top 10\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    top_10_words = [x[0] for x in words_freq[:10]]\n",
    "\n",
    "    # 5. Tworzymy DataFrame\n",
    "    df_full = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "    # 6. Top 10 słów\n",
    "    df_top = df_full[top_10_words]\n",
    "\n",
    "    # 7. Wyświetlamy dokumenty\n",
    "    print(f\"Najważniejsze słowa w tej metodzie: {top_10_words}\")\n",
    "    print(\"Poniżej tabela dla pierwszych 10 dokumentów:\")\n",
    "    display(df_top.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc8fd5-beec-4ec8-aeda-a57b99d976f3",
   "metadata": {},
   "source": [
    "### ***Binary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346d5967-062a-49dd-9458-81fe055d23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Podgląd macierzy (Wiersze = Dokumenty, Kolumny = Słowa)\")\n",
    "\n",
    "# 1. Binary (Zera i Jedynki)\n",
    "show_matrix_snippet(CountVectorizer(binary=True), clean_docs_stemmed, \"BINARY (0 = brak, 1 = jest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a88588-71d0-40f7-b1c9-3831c3852344",
   "metadata": {},
   "source": [
    "### ***Bag Of Words***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7257214-c94b-488d-8927-ce4e381c5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Podgląd macierzy (Wiersze = Dokumenty, Kolumny = Słowa)\")\n",
    "\n",
    "# 2. Bag of Words (Liczby całkowite - ile razy słowo wystąpiło)\n",
    "show_matrix_snippet(CountVectorizer(), clean_docs_stemmed, \"BAG OF WORDS (Liczba wystąpień)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6cb413-6802-4e8e-accd-c5646fa0e218",
   "metadata": {},
   "source": [
    "### ***TF-IFD***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d66cf-ef2d-4a83-9f76-b9a2bc84e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Podgląd macierzy (Wiersze = Dokumenty, Kolumny = Słowa)\")\n",
    "\n",
    "# 3. TF-IDF (Ułamki - wagi słów)\n",
    "show_matrix_snippet(TfidfVectorizer(), clean_docs_stemmed, \"TF-IDF (Wagi ważności)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bafa3-7329-4686-a41c-432ceee8eeaf",
   "metadata": {},
   "source": [
    "## # WARIANTY MACIERZY I WYNIKI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b85d4-c15c-45c3-96dd-f1b3d22a97e6",
   "metadata": {},
   "source": [
    "### ***Binarny***\n",
    "Sprawdza tylko czy słowo jest, czy go nie ma (0 lub 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bed20-09e9-4a7a-820f-79301d0922e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przy zmianie \"use_stemming=True\" na \"use_stemming=False\", trzeba zmienić nazwę pliku, aby nie nadpisać poprzednich - dodaj \"_without_stemm\"\n",
    "binary_vectorizer = CountVectorizer(binary=True)\n",
    "search_and_save(binary_vectorizer, clean_docs_stemmed, clean_queries_stemmed, raw_docs, \"Binary (0/1)\", \"wyniki_BINARY_with_stemm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f500410-8145-4564-b1c1-5f4ed222bc21",
   "metadata": {},
   "source": [
    "#### *BOW (bag of words)*\n",
    "Zlicza, ile razy słowo wystąpiło "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82922480-f987-4270-b68d-05fd2676207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przy zmianie \"use_stemming=True\" na \"use_stemming=False\", trzeba zmienić nazwę pliku, aby nie nadpisać poprzednich - dodaj \"_without_stemm\"\n",
    "bow_vectorizer = CountVectorizer()\n",
    "search_and_save(bow_vectorizer, clean_docs_stemmed, clean_queries_stemmed, raw_docs, \"Bag of Words (BOW)\", \"wyniki_BOW_with_stemm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bb20f-c8b4-4442-aa0c-3b6ad9a7ebc5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### *TF-IDF*\n",
    "Waży słowa: słowa rzadkie (unikalne) są ważniejsze niż częste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235194b-a429-4f5f-8de5-105de76fe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przy zmianie \"use_stemming=True\" na \"use_stemming=False\", trzeba zmienić nazwę pliku, aby nie nadpisać poprzednich - dodaj \"_without_stemm\"\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "search_and_save(tfidf_vectorizer, clean_docs_stemmed, clean_queries_stemmed, raw_docs, \"TF-IDF\", \"wyniki_TFIDF_with_stemm.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a1792-3f90-4b64-a19e-9e26d53031e0",
   "metadata": {},
   "source": [
    "## # WIZUALIZACJA (Word Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1fb0ba-b71f-4546-a02a-08ce719e3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalamy dokumenty\n",
    "all_text = \" \".join(clean_docs_stemmed)\n",
    "\n",
    "# generujemy chmurę słów\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
    "                      colormap='cividis', collocations=False).generate(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623a0e5-62b4-4962-92e7-896071c4baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyświetlamy wykres\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"CHMURA SŁÓW DLA ZBIORU DOKUMENTÓW\\n (po stemming)\\n\", \n",
    "          fontsize=42, \n",
    "          fontweight='bold', \n",
    "          color='darkred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b178d0-b921-43f9-a3a4-40a1b6193031",
   "metadata": {},
   "source": [
    "## # ZAPIS CHMURY DO PLIKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b4fe4-c5eb-442c-8e0e-b273ea509432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przy zmianie \"use_stemming=True\" na \"use_stemming=False\", trzeba zmienić nazwę pliku, aby nie nadpisać poprzednich - dodaj \"_without_stemm\"\n",
    "wordcloud.to_file(\"wordcloud_with_stemming.png\") \n",
    "print(\"Zapisano chmurę słów do pliku 'wordcloud_with_stemming.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9e0ea-0786-4584-a7b4-ed61a8e6c428",
   "metadata": {},
   "source": [
    "## # LICZBOWE PRZEDSTAWIENIE SŁÓW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395de26-18d2-4bf2-b0e7-9c709e6e2bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rozbijamy na pojedyńcze słowa\n",
    "words_list = all_text.split()\n",
    "\n",
    "# Counter - zliczamy słowa\n",
    "word_counts = Counter(words_list)\n",
    "\n",
    "# ranking\n",
    "top_10 = word_counts.most_common(10)\n",
    "\n",
    "print(f\"{'Miejsce':<10} {'Słowo':<20} {'Liczba wystąpień'}\")\n",
    "print(\"-\" * 50)\n",
    "for i, (word, count) in enumerate(top_10, 1):\n",
    "    print(f\"{i:<10} {word:<20} {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5593ea-524e-45de-94de-b08f8212318a",
   "metadata": {},
   "source": [
    "# PODSUMOWANIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb61dd8-02d2-40c7-8825-c0eba5ba713c",
   "metadata": {},
   "source": [
    "## 1. Metoda Binarna (Binary):\n",
    "\n",
    "- ***Wniosek***: Jest najmniej precyzyjna. Traktuje słowo, które wystąpiło raz, tak samo jak słowo, które wystąpiło 100 razy.\n",
    "\n",
    "- ***Skutek***: Często w wynikach widzimy wiele dokumentów z taką samą oceną (Score), co utrudnia stworzenie dobrego rankingu.\n",
    "\n",
    "## 2. Bag of Words (BOW):\n",
    "\n",
    "- ***Wniosek***: Lepiej niż binarna, bo uwzględnia liczebność.\n",
    "\n",
    "- ***Wada***: Faworyzuje długie dokumenty. Jeśli dokument jest bardzo długi, ma statystycznie więcej słów kluczowych, przez co może znaleźć się wysoko w rankingu, nawet jeśli słabo pasuje tematycznie.\n",
    "\n",
    "## 3. TF-IDF (Najlepsza):\n",
    "\n",
    "- ***Wniosek***: Daje najbardziej trafne wyniki.\n",
    "\n",
    "- ***Dlaczego***: Mechanizm IDF (Inverse Document Frequency) obniża wagę słów pospolitych, a podbija wagę słów unikalnych dla danego tematu. Dzięki temu, wpisując \"ceny ropy\", system ignoruje ogólne słowa biznesowe, a skupia się na tych konkretnych artykułach o ropie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
